---
title: Joining Boundary
...

# Joining Boundary

I've been in the industry for about 6 years now: the first 4 at Google
and the past 2 at [Trunk], a series-A DevEx startup that I joined pre-A.

[Trunk]: https://trunk.io/

I realized a few months ago that I wasn't excited in my role anymore, and
asked myself what I wanted to do. After a bit of looking around, I found that
the answer was that I wanted to transition to AI/ML[^why-ai-ml] - so that's
where I started.

[^why-ai-ml]: I know, I know, it is such a cliche for people to want to get into AI/ML. I actually stayed away from it for years because it felt like such a cliche.

    But specifically with the advent of LLMs,, it feels like we've reached a turning point where this technology is now actually
    accessible to the average developer, and that we're seeing steady progress
    (sometimes in huge leaps) particularly because we've somehow
    gotten to a point where, between the transformer architecture and Moore's
    law, we can just throw obscene amounts of compute at problems to solve them.

I ended up with two offers:

  * one from [Boundary], a no-name seed-stage AI/ML startup with 2 co-founders
    and 0 employees, and
  * one from OpenAI.

I chose to join [Boundary].

[Boundary]: https://www.boundaryml.com/.

## Why? - the short version

I was **excited** about Boundary, in a way that I wasn't about OpenAI.

I actually originally decided that I was going to join OpenAI and turn down
Boundary - or as Vaibhav, one of Boundary's co-founders, put it, "make the
objectively sane decision".

But the first time I told a friend I was going to join OpenAI, I couldn't help
but feel like I was turning down a chance to do something big. That feeling
stuck with me when I told a second friend, and was still there when I told a
third friend.

So when Vaibhav called me to pitch me one last time, I realized that right now,
the decision that makes me happy - the decision that makes me _excited_ - is
joining Boundary.


## Why? - the long version

This was the first time I've ever had the luxury of being able to choose between
two amazing, two very different opportunities. It took me a long time - three,
maybe four weeks - to actually come to a decision.

I realized, at some point, that the question I needed to ask myself was "what do
I want to do in life?", and for me, the answer is that I want to do something
that matters, and ideally, I'd like to build it from the ground up.

There's absolutely an appeal to building resilient training infrastructure,
to building a scalable system from zero, to taking a system from 99% available
to 99.99% available (or even 99.999%). But it would be even cooler to be able to
do all that for something that I've built from scratch - and that was what
pushed me towards Boundary.

It took me a long time to get to this realization though. I went through all the
criteria[^criteria-order] that I could think of, and then some:

  * money
  * career opportunity
  * product opportunity (both absolute and relative[^absolute-and-relative])
  * timing (both product-in-industry timing and personal timing)
  * culture (people and values)
  * learning opportunity[^learning-opportunity]
  * location
  * doing something else

[^criteria-order]: I've ordered these criteria in roughly the order in which
    they came to mind, which is similar to but not equal to an order by
    importance. I don't think I could actually stack rank these criteria,
    because the ordering would change from situation to situation.
[^absolute-and-relative]: The way I always describe the $bigco vs. $startup
    decision is that at $bigco, you'll have the opportunity to have huge
    absolute impact, but small relative impact (e.g. the Windows Task Manager is
    an entire team; Chrome Sync is an entire team) whereas at $startup, you'll
    have small absolute impact, but huge relative impact (i.e. maybe you'll get
    to 100K users, but all of those users will know what you've built).
[^learning-opportunity]: No, I don't like putting the third "opportunity"
    further down the list. But this is a more true order for this list.


## Money

OpenAI compensation is impressive:

<figure>
  <img src="/assets/openai-levels-fyi.png" />
  <figcaption>
    levels.fyi OpenAI compensation data
    (<a href="https://www.levels.fyi/companies/openai/salaries/software-engineer/levels/l5">source</a>)
  </figcaption>
</figure>

But money, past a certain point, has diminishing value. I'm not trying to retire
early. I'm not looking to go heli-skiing once a month. I'm not even planning on
buying a house anytime soon.

I'm fortunate enough to earn enough that I do not, and will never have to worry
about making rent. I don't have to buy groceries based on what's on sale. I can
comfortable fund all my hobbies (climbing, skiing, and photography). And I'm confident in the stability of my earning
potential.

That's enough for me.

I know too many people who've optimized for money at the expense of their time,
energy, and youth, and I don't want to be one of them.

## Career Opportunity

Or, phrased alternatively, the ability to do anything I want to do.

With Google, my [resume](/resume) is pretty darn solid. With
OpenAI[^openai-role], it would've been bulletproof - especially for future AI/ML
opportunities.

[^openai-role]: I would've joined a new team being spun up to build new training
    infrastructure. In other words: as close to the AI/ML research as I can get
    without getting a PhD.

With Boundary, it's a very different career opportunity:

  * It's going to mean defining what the AI/ML developer experience looks like, 5
    years from now.

  * It's going to mean tackling a lot of Hard Problemsâ„¢, from building a compiler
    to defining our infrastructure patterns to building our brand identity.

  * I know that I can learn a lot from Vaibhav and Aaron - the Boundary
    co-founders - in everything from technical instincts to product thinking
    to leadership skills.

  * It's _not_ going to have household-level brand recognition - plus, there's
    a very real chance that we won't make it.

Most importantly: it's the opportunity to build something big, and to build it
from scratch. OpenAI is doing amazing things - just look at [what they're doing
with video!][openai-sora] - but I wouldn't be starting from zero.

And if the goal of career experience is to get to a point you can do anything
you want to do, and I've got a reasonably future-proofed resume already, well -
if one of my options is to do what I want to do, why not take that one?

[openai-sora]: https://openai.com/sora

## Product Opportunity

One friend suggested that I can look at OpenAI in one of two ways: either it's
Yahoo - it's already made it, and it's only downhill from here - or it's Google
in the mid 2000s, and who wouldn't want to join that?

But again, regardless of which of the two it is, when I compare that to the
opportunity to do something big, something that's actually interesting to me,
and to build it from zero, it's hard for that to compare.

Most startups, at least to me, are not interesting. They might be academically
interesting to me - e.g. I can see why this is a hard problem, and yes, it's
absurd that no one's solved this yet - but they're not working on problems that
interest me.

Boundary, by contrast, is aiming to create a new, high-quality, open-source ML
development experience. That, to me at least, means a lot of hard, interesting
problems, and if Boundary's vision was anything less than that, I would've
joined OpenAI.

  * We want to give people the right abstractions to **build** on top of their
    ML models: everything from inline comments that get stripped from your LLM
    prompts to support for Python and Typescript and making it easy to switch
    between ML service providers.

  * We want to enable people to **test** the ML features and products that
    they're building, which is especially important when you're dealing with
    probabilistic systems and defining correctness is harder than enumerating
    edge cases!

  * We want it to be easy to **deploy** changes to your ML features:
    you should be able to both self-host everything that calls an OpenAI API and
    ask us to handle that for you, function-as-a-service style.

  * We want our users to be able to **monitor** their ML usage and ask
    questions about the precision and recall of their deployed model, about
    the costs of the current deployment, and about the reliability of the
    current deployment.

  * We want it to be straightforward to **refine** your ML usage, whether that
    means LLM prompt tuning, fine-tuning an existing open-source model, or
    training a special-purpose model from scratch.

And we think that the right way to do all this is to start with:

  * a freely available, open-source schema language for your ML APIs,
  * code generation for your LLM interactions, and
  * robust, fast, easy-to-use tooling to support every step of the process.

Importantly, this approach has a number of advantages compared to competitors in
the space (I may or may not have put together a spreadsheet at 2am at one point
to assess this):

  * We can offer our users a flexible, end-to-end platform. No one likes stitching
      together 10 products to build their workflow.

  * We don't have lock-in: our schema language, compiler, and IDE integrations
      are all freely available and open-source, so if users want to use just
      those, they're more than welcome to.

  * We can build our platform and ecosystem incrementally. Every platform
      suffers from the critical mass challenge - that you have to build out an
      entire platform for using it to be attractive, and then get enough
      adoption to accrue network effects - but everything that we want to build
      will be independently useful, so we'll be able to respond much more
      quickly to our users as we build out.

  * We're not tied to LLMs: if the winds shift and the industry discovers new
      model architectures, hosting patterns, or whatnot, we'll be
      well-positioned to respond, because our value proposition is giving
      you the right abstractions for your ML APIs. We have a lot of special
      support for working with LLMs, because the existing general-purpose LLMs
      are wildly useful. But there's definitely some insanity to the fact that
      API calls in the LLM world can and do take multiple seconds.

That's the pitch.

It's long - we're still working on it. But with Boundary, I get to be part of
that journey, whereas at OpenAI, they have answers to a lot of these questions
around what to build, how to build them, and an established leadership/executive
team to iterate on those answers. (And I do believe that OpenAI now has
fundamental execution risk around the [innovator's dilemma].)

[innovator's dilemma]: https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma

## Timing

I'm very confident that the products, companies, organizations, and technologies
that will be dominant in 5 years are getting started now. As confident (or as
arrogant!) as someone in their late 20s can be, I guess.

Looking at the past waves that made it big - cloud, mobile, sharing
economies, IoT[^iot], social, PCs, internet - and all those that didn't - VR,
blockchain[^blockchain], no-code, 3D printing - there's very clear value
creation that LLMs specifically have enabled, and the AI spring that we're in
right now feels here to stay.

[^iot]: IoT feels weird in this list. It's unquestionably been huge - not just
    Google Home and Alexa, but Square/Clover point-of-sale terminals, LG smart
    fridges, Samsung laundry machines, Nest thermostats, Ring doorbells - but it
    feels an order of magnitude smaller than, say, mobile. People in developing
    countries who don't have running water have phones - that's how big mobile
    is. IoT, or at least the way I think of it, internet-connected embedded
    devices, is not that big.
[^blockchain]: Oh, yes, digital assets are a thing. But I can't point to a
    single thing in the blockchain space that has created real, substantive
    value beyond novel financial currencies/instruments. And not novel in the
    way that the creation of credit cards and checking accounts enabled safer,
    easier consumer fiance and more efficient capital utilization, but novel in
    the way that mortgage-backed securities were another means for finance
    professionals to allocate capital and generate returns.

The top challenge right now feels mostly like implementation - namely, the fact
that ML operational costs (and, to a similar extent, capex as well) are growing
exponentially as capabilities improve. Every wave that became big was able to to
do so off the back of diminishing costs, either in the form of Moore's law or
network effects.

With OpenAI, the timing factor is that I would be joining as a cog in the
machine. A large cog, yes, because I have no doubt that they're going to
continue growing at a truly insane pace, but still one of many.

### Personal timing

It also helps that I don't have a partner, I don't have kids, and I don't have a
house right now. If any of those change, and I need something more stable and
less risky in the future - well, I don't know if I'll have the risk tolerance
for something like this at that point.

## Culture: people and values

Vaibhav and Aaron are incredibly smart, capable, and thoughtful people - I've
known them for years now, and if there's anyone I know that can pull it off,
it's them. I don't say that lightly: I've had the privilege to work with a lot
of really amazing people.

They've got the technical credentials: Vaibhav's worked on everything from
bringing Face Unlock to the Google Pixel to building custom Python runtimes;
Aaron rewrote AWS EC2's internal telemetry system to get rid of its scaling
bottlenecks.

The ways we worked through all the disagreements[^disagreements] we had (and we
had a lot of them!) during my week-long work trial convinced me that they're
thoughtful, respectful people who I can not only be honest with, but also learn
from even when we disagree.

[^disagreements]: a.k.a. arguments

(Yes, a week-long work trial is pretty ridiculous - I certainly took a lot of
convincing to do it - but ultimately I'm glad I did it. It ended up being just
as much them interviewing me, as it was me interviewing them. Not only did we
work through a lot of diagreements, but we also talked a lot about all our
communication styles, and our own strengths and weaknesses.)

Regardless of whether or not we succeed, I'll be excited to spend the next
few years working alongside them, learning from them, trying to do something big.

We're all clear that this journey is only worth it if we have fun along the way,
if we build an environment where we enjoy each others' company, that we
consider that vital to our success, and that this will require very conscious
and deliberate effort as we grow.

OpenAI, by contrast, is now big enough that they're concerned about leaks.

## Learning Opportunity

One of my favorite things about Google was the sheer amount of learning
opportunities I was surrounded by. I was able to not only get my hands dirty
deep in the guts of Bigtable, Spanner, MapReduce, Borg, and Chubby, but I was
also able to go and learn about how web search and indexing worked, how YouTube
video uploads worked, how Google did load balancing, so on and so forth. I loved
being able to go "I wonder how this thing works" and then actually _reading the
design documents that people wrote as they were building the thing_.

This was not a thing that most people did. It's part of the appeal of being at
Google, I think - but most people never take advantage of it. I realized that
about a year in, that one of the reasons I had wanted to join was because of the
learning opportunities. That was when I started sponging up knowledge - about
how YouTube transcoding works, about how our monitoring system dealt with fan-in
problems, about how search was unified across multiple Google products.

I have no doubt I would get this at OpenAI, where I'd be able to avail myself of
world-class experts and being on the inside of impressive technologies at scale.

But at Boundary, I expect my learning to come from, well, building. I do have
specific goals for how I want to focus my learning, and if our execution path
ends up at odds with that (I certainly don't intend to spend any time doing
resume-driven development), well, we'll cross that bridge when we get to it.

## Location

I'll be moving to Seattle for Boundary[^in-person]; if I'd joined OpenAI, I
would've had to move back to San Francisco.

[^in-person]: Vaibhav and Aaron both live in Seattle, and all three of us
    strongly believe that being in an office, together, will make it much easier
    for us to communicate effectively and spontaneously than if I was remote.

Both are amazing cities: there are plenty of smart, interesting people in both,
and they both have great access to climbing and skiing (the two sports that I
fell in love with during the pandemic).

But, when it comes to San Francisco, I just couldn't bring myself to be excited
about moving back there. I actually literally spent 12 hours driving to San
Francisco, while I was deciding between Boundary and OpenAI, in part to meet the
OpenAI team, but really because I wanted to see if I could find it in me to be
excited about moving back there. And I couldn't.

(Admittedly, I did also ask myself whether OpenAI allowing remote would change
my decision - not that this was on the table; I just wanted to ask myself the
hypothetical to figure out if it would make a difference - and it wouldn't have
made a difference. For a different pair of locations and opportunities, though?
That decision calculus could definitely have made the difference.)

## Why not be a founder myself?

I don't know if it's a thing I want to do.

Founding means putting 200% of yourself into the business, 24/7, for years - I
wouldn't want to do it without dedicating at least 100%, and that's just not
a balance of priorities that I'm willing to accept for myself at this stage of
my life. Possibly ever.

(There's also a little bit of an activation energy / escape velocity / critical
mass problem, where I'd need an idea that I'm passionate about, a co-founder who
I'm willing to spend years working alongside, and stability in the other
aspects of my life - and I think you only get there if you just dive in
head-first, sink-or-swim style.)

### Or just something else?

I would love to do something like the [Recurse Center] at some point. Or take
more time off. I could, in theory, quit for a year and just gallivant around the
country or the world. But I don't think I would get the same fulfillment out of
any of those as getting back on the wagon again.

[Recurse Center]: https://www.recurse.com/

## Making the decision

It took me so, _so_ long to make this decision (and Vaibhav, Aaron, I really
appreciate how long you gave me to make it). I talked to almost everyone I know
about it, tried the trick of "flip a coin and see if you're happy or not", and
spent weeks paralyzed by indecision.

Semi-committing to an option, and telling friends that I had decided to join
OpenAI, and telling friends that I had decided to join Boundary - that was the
litmus test I needed.

I'm happy with the decision I made, and confident that in 5 years, that in 10
years, I'll be able to look back on this decision and be convinced I made the
right call, regardless of whether or not Boundary succeeds.

Because even if we fail - and all the startup numbers say we will - at least
I'll have tried to do something big, and I know we'll have fun along the way.

## Aside: self-reflection

Throughout this entire process - thinking about what I wanted to do next,
whether I wanted to do _anything_ next, what kinds of things I was qualified to
do - there was also a lot of reflection about myself:

  * what I've achieved
  * what I want to achieve
  * where in my career progression I am
  * what direction I want my progression to take
  * what I want to do with my life

And it was a really valuable experience. Highly recommend, 10/10.
